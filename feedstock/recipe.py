#!/usr/bin/env python3

import os
import glob
import logging

from dask.distributed import Client, LocalCluster
import gcsfs
import xarray as xr
from pathlib import Path
from dask.diagnostics import ProgressBar

# â”€â”€â”€ Clean Up Previous Log Files â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
for log_file in Path(".").glob("*.log"):
    try:
        log_file.unlink()
        print(f"ðŸ—‘ï¸  Deleted old log file: {log_file}")
    except Exception as e:
        print(f"âš ï¸  Could not delete {log_file}: {e}")

# â”€â”€â”€ Remove old log files â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
for logfile in glob.glob("*.log"):
    try:
        os.remove(logfile)
    except OSError:
        pass

# â”€â”€â”€ Logging Configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
logging.basicConfig(
    filename="recipe_CSIF.log",
    level=logging.INFO,
    format="%(asctime)s %(levelname)s %(message)s",
)
logger = logging.getLogger(__name__)


def get_chunk_scheme(total_time, lat_size, lon_size, dtype_bytes, target_MB=125):
    """Compute chunks so that each chunk â‰² target_MB MB."""
    time_chunk = total_time
    allowed = target_MB * 1024**2
    max_spatial = allowed / (time_chunk * dtype_bytes)

    ratio = lat_size / lon_size
    lat_chunk = int((max_spatial * ratio) ** 0.5)
    lon_chunk = int((max_spatial / ratio) ** 0.5)

    lat_chunk = max(1, min(lat_size, lat_chunk))
    lon_chunk = max(1, min(lon_size, lon_chunk))

    return {"time": time_chunk, "lat": lat_chunk, "lon": lon_chunk}


def main():
    logger.info("ðŸš€ CSIF recipe starts")

    # â”€â”€â”€ start Dask cluster â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # cluster = LocalCluster(n_workers=2, threads_per_worker=2, memory_limit='20GB')
    cluster = LocalCluster(
        n_workers=8,  # â† Change from 4 to 8 workers
        threads_per_worker=1,  # â† Keep 1 thread per worker (best for I/O tasks like Zarr writing)
        memory_limit="7GB",  # â† Each worker uses max 5 GB (because 8Ã—5 = 40GB total; fits your system)
        processes=True,  # â† Default, but good to be explicit (one process per worker)
        dashboard_address=None,
    )  # â† If you want a dashboard, can change to ':8787'
    # 72 files of 1.6GB are read and 54 chunks are written 80% of memory is reached, each batch takes about 2 minutes to be written
    client = Client(cluster)

    # â”€â”€â”€ set up GCS paths â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    fs = gcsfs.GCSFileSystem()
    base_path = "leap-scratch/mitraa90/GLAB-CSIF/"
    zarr_store = "gs://leap-persistent/data-library/GLAB-CSIF/GLAB-CSIF.zarr"
    fs.mkdirs(os.path.dirname(zarr_store), exist_ok=True)

    # â”€â”€â”€ find all .nc files â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    gcs_paths = fs.glob(f"{base_path}**/*.nc")
    print(f"Found {len(gcs_paths)} NetCDF files.", flush=True)
    if not gcs_paths:
        return

    # â”€â”€â”€ peek metadata from a single file â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("Reading lat/lon sizes + dtype from one fileâ€¦", flush=True)
    with fs.open(gcs_paths[0], "rb") as f:
        ds0 = xr.open_dataset(f, engine="h5netcdf", chunks={"time": 1})
    lat_size = ds0.sizes["lat"]
    lon_size = ds0.sizes["lon"]
    var = next(iter(ds0.data_vars))
    dtype_bytes = ds0[var].dtype.itemsize
    ds0.close()
    print(f"  â†’ lat={lat_size}, lon={lon_size}, bytes/pt={dtype_bytes}", flush=True)

    # â”€â”€â”€ set batch (time) size and build chunks â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    batch_size = 72
    chunks = {
        "time": batch_size,
        "lat": 600,
        "lon": 800,
    }  # get_chunk_scheme(total_time, lat_size, lon_size, dtype_bytes, target_MB=125)
    print("Using chunk scheme:", chunks, flush=True)

    # â”€â”€â”€ process in batches â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    batches = [
        gcs_paths[i : i + batch_size] for i in range(0, len(gcs_paths), batch_size)
    ]
    if len(gcs_paths) % batch_size != 0:
        raise ValueError(
            f"âŒ Number of files ({len(gcs_paths)}) is not evenly divisible by batch_size ({batch_size}). "
            f"Please choose a batch_size that divides evenly into {len(gcs_paths)} otherwise, append commend fails at the last batch."
        )

    for i, batch in enumerate(batches, 1):
        print(f"\nðŸ“‚ Batch {i}/{len(batches)}: opening {len(batch)} filesâ€¦", flush=True)
        ds = xr.open_mfdataset(
            [fs.open(p, "rb") for p in batch],
            engine="h5netcdf",
            chunks={"time": 1},  # small chunks while loading (safe)
            combine="by_coords",
            parallel=True,
        )
        print(" DS opened and is to be chunked")
        ds = ds.chunk(chunks)
        vname = "lcspp_clear_daily"  # or any main variable you are chunking

        print(
            f"  â†’ DS is chunked: time={ds.sizes['time']} (chunk {ds[vname].data.chunks[0]}), "
            f"lat={ds.sizes['lat']} (chunk {ds[vname].data.chunks[1]}), "
            f"lon={ds.sizes['lon']} (chunk {ds[vname].data.chunks[2]})",
            flush=True,
        )

        mode = "w" if i == 1 else "a"
        consolidated = True if i == 1 else False
        print(f"  â†’ Writing batch to Zarr (mode={mode})â€¦", flush=True)
        append_dim = "time" if i > 1 else None

        with ProgressBar():
            ds.to_zarr(
                zarr_store,
                mode=mode,
                append_dim=append_dim,
                consolidated=consolidated,
                compute=True,
            )
        print(f"  âœ… Batch {i} written.", flush=True)

        ds.close()

    client.close()
    cluster.close()
    logger.info("ðŸš€ CSIF recipe ends")


if __name__ == "__main__":
    main()
